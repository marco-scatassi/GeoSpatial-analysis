{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "from kedro.io import DataCatalog\n",
    "from kedro.config import ConfigLoader\n",
    "from kedro.runner import ParallelRunner\n",
    "from kedro.framework.project import settings\n",
    "from kedro.framework.session import KedroSession\n",
    "from kedro.extras.datasets.json import JSONDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [f\"{day}_04_2023\" for day in range(20, 31)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data ingestion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_ingestion_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\ingestion.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_ingestion_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "    elements_in_file = len(re.findall(r\"(ingestion.date\\d: .*\\n)\", contents))\n",
    "    elements_to_write = len(dates)\n",
    "    \n",
    "    if elements_in_file < elements_to_write:\n",
    "        if elements_in_file == 0:\n",
    "            s = \"\"\n",
    "            for i in range(0, elements_to_write):\n",
    "                s += f'ingestion.date{i}: \\n'\n",
    "            contents = \"\\n\".join([s])\n",
    "        else:\n",
    "            start = elements_in_file-1\n",
    "            s = f'ingestion.date{start}: \\n'\n",
    "            for i in range(elements_in_file, elements_to_write):\n",
    "                s += f'ingestion.date{i}: \\n'\n",
    "            contents = re.sub(fr\"(ingestion.date{elements_in_file-1}: .*\\n)\", s, contents)\n",
    "            \n",
    "    for i, date in enumerate(dates):\n",
    "        contents = re.sub(fr\"(ingestion.date{i}: .*\\n)\", f'ingestion.date{i}: \"{date}\"\\n', contents)\n",
    "    \n",
    "    if elements_in_file > elements_to_write:\n",
    "        for i in range(elements_to_write, elements_in_file+1):\n",
    "            contents = re.sub(fr\"(ingestion.date{i}: .*\\n)\", f'ingestion.date{i}: \\n', contents)\n",
    "\n",
    "    \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingestion.date0: \"20_04_2023\"\n",
      "ingestion.date1: \"21_04_2023\"\n",
      "ingestion.date2: \"22_04_2023\"\n",
      "ingestion.date3: \"23_04_2023\"\n",
      "ingestion.date4: \"24_04_2023\"\n",
      "ingestion.date5: \"25_04_2023\"\n",
      "ingestion.date6: \"26_04_2023\"\n",
      "ingestion.date7: \"27_04_2023\"\n",
      "ingestion.date8: \"28_04_2023\"\n",
      "ingestion.date9: \"29_04_2023\"\n",
      "ingestion.date10: \"30_04_2023\"\n",
      "ingestion.date10: \"30_04_2023\"\n",
      "ingestion.date10: \"30_04_2023\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data cleaning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_cleaning_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\cleaning.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bergen_polygon_vertex = [\n",
    "     [5.161214, 60.372825],\n",
    "     [5.211224, 60.398977],\n",
    "     [5.255800, 60.409478],\n",
    "     [5.240007, 60.479588],\n",
    "     [5.259292, 60.528707],\n",
    "     [5.322314, 60.545026],\n",
    "     [5.542953, 60.421316],\n",
    "     [5.486513, 60.348389],\n",
    "     [5.343004, 60.257903],\n",
    "     [5.256487, 60.240867],\n",
    "     [5.227651, 60.242074],\n",
    "     [5.190497, 60.291077],\n",
    "     [5.197846, 60.325154],\n",
    "     [5.183965, 60.337078],\n",
    "     [5.169675, 60.340815],\n",
    "     [5.161214, 60.372825]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_cleaning_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "    elements_in_file = len(re.findall(r\"(cleaning.date\\d: .*\\n)\", contents))\n",
    "    elements_to_write = len(dates)\n",
    "    \n",
    "    if elements_in_file < elements_to_write:\n",
    "        s = \"\"\n",
    "        if elements_in_file == 0:\n",
    "            for i in range(0, elements_to_write):\n",
    "                s += f'cleaning.date{i}: \\n'\n",
    "            contents = \"\\n\".join([s])\n",
    "        else:\n",
    "            start = elements_in_file-1\n",
    "            s = f'cleaning.date{start}: \\n'\n",
    "            for i in range(elements_in_file, elements_to_write):\n",
    "                s += f'cleaning.date{i}: \\n'\n",
    "            contents = re.sub(fr\"(cleaning.date{elements_in_file-1}: .*\\n)\", s, contents)\n",
    "            \n",
    "    for i, date in enumerate(dates):\n",
    "        contents = re.sub(fr\"(cleaning.date{i}: .*\\n)\", f'cleaning.date{i}: \"{date}\"\\n', contents)\n",
    "    \n",
    "    if elements_in_file > elements_to_write:\n",
    "        for i in range(elements_to_write, elements_in_file+1):\n",
    "            contents = re.sub(fr\"(cleaning.date{i}: .*\\n)\", f'cleaning.date{i}: \\n', contents)\n",
    "    \n",
    "    if \"cleaning.polygon_vertex\" not in contents:\n",
    "        contents += f\"\\ncleaning.polygon_vertex: {bergen_polygon_vertex}\\n\"\n",
    "    else:\n",
    "        contents = re.sub(r\"(cleaning.polygon_vertex: .*\\n)\", f\"cleaning.polygon_vertex: {bergen_polygon_vertex}\\n\", contents)\n",
    "        \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning.date0: \"20_04_2023\"\n",
      "cleaning.date1: \"21_04_2023\"\n",
      "cleaning.date2: \"22_04_2023\"\n",
      "cleaning.date3: \"23_04_2023\"\n",
      "cleaning.date4: \"24_04_2023\"\n",
      "cleaning.date5: \"25_04_2023\"\n",
      "cleaning.date6: \"26_04_2023\"\n",
      "cleaning.date7: \"27_04_2023\"\n",
      "cleaning.date8: \"28_04_2023\"\n",
      "cleaning.date9: \"29_04_2023\"\n",
      "cleaning.date10: \"30_04_2023\"\n",
      "cleaning.date10: \"30_04_2023\"\n",
      "\n",
      "cleaning.polygon_vertex: [[5.161214, 60.372825], [5.211224, 60.398977], [5.2558, 60.409478], [5.240007, 60.479588], [5.259292, 60.528707], [5.322314, 60.545026], [5.542953, 60.421316], [5.486513, 60.348389], [5.343004, 60.257903], [5.256487, 60.240867], [5.227651, 60.242074], [5.190497, 60.291077], [5.197846, 60.325154], [5.183965, 60.337078], [5.169675, 60.340815], [5.161214, 60.372825]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to GeoPandasDf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_convert_to_gdf_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\convert_to_gdf.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [f\"{day}_04_2023\" for day in range(20, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_convert_to_gdf_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "    elements_in_file = len(re.findall(r\"(convert_to_gdf.date\\d: .*\\n)\", contents))\n",
    "    elements_to_write = len(dates)\n",
    "    \n",
    "    if elements_in_file < elements_to_write:\n",
    "        s = \"\"\n",
    "        if elements_in_file == 0:\n",
    "            for i in range(0, elements_to_write):\n",
    "                s += f'convert_to_gdf.date{i}: \\n    day: \\n'\n",
    "            contents = \"\\n\".join([s])\n",
    "        else:\n",
    "            start = elements_in_file-1\n",
    "            s = f'convert_to_gdf.date{start}: \\n    day: \\n'\n",
    "            for i in range(elements_in_file, elements_to_write):\n",
    "                s += f'convert_to_gdf.date{i}: \\n    day: \\n'\n",
    "            contents = re.sub(fr\"(convert_to_gdf.date{elements_in_file-1}: .*\\n    day: .*\\n)\", s, contents)\n",
    "            \n",
    "    for i, date in enumerate(dates):\n",
    "        contents = re.sub(fr\"(convert_to_gdf.date{i}: .*\\n    day: .*\\n)\", \n",
    "                          f'convert_to_gdf.date{i}: \\n    day: \"{date}\"\\n', contents)\n",
    "    \n",
    "    if elements_in_file > elements_to_write:\n",
    "        for i in range(elements_to_write, elements_in_file):\n",
    "            contents = re.sub(fr\"(convert_to_gdf.date{i}: .*\\n    day: .*\\n)\", \n",
    "                              f'convert_to_gdf.date{i}: \\n    day: \\n', contents)\n",
    "\n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_gdf.date0: \n",
      "    day: \"20_04_2023\"\n",
      "convert_to_gdf.date1: \n",
      "    day: \"21_04_2023\"\n",
      "convert_to_gdf.date2: \n",
      "    day: \"22_04_2023\"\n",
      "convert_to_gdf.date3: \n",
      "    day: \"23_04_2023\"\n",
      "convert_to_gdf.date4: \n",
      "    day: \"24_04_2023\"\n",
      "convert_to_gdf.date5: \n",
      "    day: \"25_04_2023\"\n",
      "convert_to_gdf.date6: \n",
      "    day: \"26_04_2023\"\n",
      "convert_to_gdf.date7: \n",
      "    day: \"27_04_2023\"\n",
      "convert_to_gdf.date8: \n",
      "    day: \"28_04_2023\"\n",
      "convert_to_gdf.date9: \n",
      "    day: \"29_04_2023\"\n",
      "convert_to_gdf.date10: \n",
      "    day: \"30_04_2023\"\n",
      "convert_to_gdf.date10: \n",
      "    day: \"30_04_2023\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create average GeoDataFrames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set average GeoDataFrames parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_create_average_gdfs_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\create_average_gdfs.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [f\"{day}_04_2023\" for day in range(20, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_create_average_gdfs_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    if re.findall(r\"(create_average_gdfs.days: .*\\n)\", contents) == []:\n",
    "        contents = \"\\n\".join([contents, f\"create_average_gdfs.days: {days}\\n\"])\n",
    "    else:\n",
    "        contents = re.sub(r\"(create_average_gdfs.days: .*\\n)\", f\"create_average_gdfs.days: {days}\\n\", contents)\n",
    "    \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "create_average_gdfs.days: ['20_04_2023', '21_04_2023', '22_04_2023', '23_04_2023', '24_04_2023', '25_04_2023', '26_04_2023', '27_04_2023', '28_04_2023', '29_04_2023', '30_04_2023']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create worst average GeoDataFrames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set worst average GeoDataFrames parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_create_worst_average_gdfs_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\build_worst_average_gdfs.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [f\"{day}_04_2023\" for day in range(20, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_create_worst_average_gdfs_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    if re.findall(r\"(build_worst_average_gdfs.days: .*\\n)\", contents) == []:\n",
    "        contents = \"\\n\".join([contents, f\"build_worst_average_gdfs.days: {days}\\n\"])\n",
    "    else:\n",
    "        contents = re.sub(r\"(build_worst_average_gdfs.days: .*\\n)\", f\"build_worst_average_gdfs.days: {days}\\n\", contents)\n",
    "    \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This is a boilerplate parameters config generated for pipeline 'build_worst_average_gdfs'\n",
      "# using Kedro 0.18.7.\n",
      "#\n",
      "# Documentation for this file format can be found in \"Parameters\"\n",
      "# Link: https://docs.kedro.org/en/0.18.7/kedro_project_setup/configuration.html#parameters\n",
      "\n",
      "build_worst_average_gdfs.days: ['20_04_2023', '21_04_2023', '22_04_2023', '23_04_2023', '24_04_2023', '25_04_2023', '26_04_2023', '27_04_2023', '28_04_2023', '29_04_2023', '30_04_2023']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build average Graph and Adj Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [\"all_day\", \"morning\", \"midday\", \"afternoon\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_build_average_graph_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\build_average_graphs.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_build_average_graph_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    for i in range(0, len(times)):\n",
    "        if re.findall(fr\"(build_average_graphs.{times[i]}: .*\\n)\", contents) == []:\n",
    "            contents = \"\\n\".join([contents, f\"build_average_graphs.{times[i]}: {times[i]}\\n\"])\n",
    "        else:\n",
    "            contents = re.sub(r\"(build_average_graphs.{times[i]}: .*\\n)\", f\"build_average_graphs.{times[i]}: {days}\\n\", contents)\n",
    "    \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This is a boilerplate parameters config generated for pipeline 'build_average_graphs'\n",
      "# using Kedro 0.18.7.\n",
      "#\n",
      "# Documentation for this file format can be found in \"Parameters\"\n",
      "# Link: https://docs.kedro.org/en/0.18.7/kedro_project_setup/configuration.html#parameters\n",
      "\n",
      "build_average_graphs.all_day: all_day\n",
      "\n",
      "build_average_graphs.morning: morning\n",
      "\n",
      "build_average_graphs.afternoon: afternoon\n",
      "\n",
      "build_average_graphs.evening: evening\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adj matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_build_adjacency_matrix_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\build_adjacency_matrix.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_build_adjacency_matrix_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    for i in range(0, len(times)):\n",
    "        if re.findall(fr\"(build_adjacency_matrix.{times[i]}: .*\\n)\", contents) == []:\n",
    "            contents = \"\\n\".join([contents, f\"build_adjacency_matrix.{times[i]}: {times[i]}\\n\"])\n",
    "        else:\n",
    "            contents = re.sub(r\"(build_adjacency_matrix.{times[i]}: .*\\n)\", f\"build_adjacency_matrix.{times[i]}: {days}\\n\", contents)\n",
    "    \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This is a boilerplate parameters config generated for pipeline 'build_adjacency_matrix'\n",
      "# using Kedro 0.18.7.\n",
      "#\n",
      "# Documentation for this file format can be found in \"Parameters\"\n",
      "# Link: https://docs.kedro.org/en/0.18.7/kedro_project_setup/configuration.html#parameters\n",
      "\n",
      "build_adjacency_matrix.all_day: all_day\n",
      "\n",
      "build_adjacency_matrix.morning: morning\n",
      "\n",
      "build_adjacency_matrix.midday: midday\n",
      "\n",
      "build_adjacency_matrix.afternoon: afternoon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_solution_comparison_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\solution_comparison.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_solution = \"all_day_free_flow\"\n",
    "data_key = [\"time_solution\", \"time_scenario\", \"weight\", \"worst\"]\n",
    "\n",
    "time_scenarios = [(\"all_day\", \"weight2\",\"False\"), (\"all_day\", \"weight\",\"False\"), (\"morning\", \"weight\",\"False\"), (\"midday\", \"weight\",\"False\"), (\"afternoon\", \"weight\",\"False\"),\n",
    "                  (\"all_day\", \"weight2\",\"True\"), (\"all_day\", \"weight\",\"True\"), (\"morning\", \"weight\",\"True\"), (\"midday\", \"weight\",\"True\"), (\"afternoon\", \"weight\",\"True\")]\n",
    "data = [{\"time_solution\": time_solution, \"time_scenario\": time_scenario[0], \"weight\": time_scenario[1], \"worst\": time_scenario[2]} for time_scenario in time_scenarios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_comparison0: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight2\"\n",
      "    worst: \"False\"\n",
      "solution_comparison1: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"\n",
      "solution_comparison2: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"morning\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"\n",
      "solution_comparison3: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"midday\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"\n",
      "solution_comparison4: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"afternoon\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"\n",
      "solution_comparison5: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight2\"\n",
      "    worst: \"True\"\n",
      "solution_comparison6: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"\n",
      "solution_comparison7: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"morning\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"\n",
      "solution_comparison8: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"midday\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"\n",
      "solution_comparison9: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"afternoon\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"\n"
     ]
    }
   ],
   "source": [
    "with open(root_solution_comparison_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "    elements_in_file = len(re.findall(r\"(solution_comparison\\d: .*\\n)\", contents))\n",
    "    elements_to_write = len(data)\n",
    "    \n",
    "    if elements_in_file < elements_to_write:\n",
    "        s = \"\"\n",
    "        if elements_in_file == 0:\n",
    "            for i in range(0, elements_to_write):\n",
    "                s += f'solution_comparison{i}: \\n    time_solution:\\n    time_scenario:\\n    weight:\\n    worst:\\n'\n",
    "            contents = \"\\n\".join([s])\n",
    "        else:\n",
    "            start = elements_in_file-1\n",
    "            s = f'solution_comparison{start}: \\n    time_solution:\\n    time_scenario:\\n    weight:\\n    worst:\\n'\n",
    "            for i in range(elements_in_file, elements_to_write):\n",
    "                s += f'solution_comparison{i}: \\n    time_solution:\\n    time_scenario:\\n    weight:\\n    worst:\\n'\n",
    "            contents = re.sub(fr\"(solution_comparison{elements_in_file-1}: .*\\n    time_solution: .*\\n    time_scenario: .*\\n    weight: .*\\n    worst: .*\\n)\", s, contents)\n",
    "            \n",
    "    for i, d in enumerate(data):\n",
    "        contents = re.sub(fr\"(solution_comparison{i}: .*\\n    time_solution: .*\\n    time_scenario: .*\\n    weight: .*\\n    worst: .*\\n)\", \n",
    "                          f'solution_comparison{i}: \\n    time_solution: \"{d[data_key[0]]}\"\\n    time_scenario: \"{d[data_key[1]]}\"\\n    weight: \"{d[data_key[2]]}\"\\n    worst: \"{d[data_key[3]]}\"', contents)\n",
    "        print(f'solution_comparison{i}: \\n    time_solution: \"{d[data_key[0]]}\"\\n    time_scenario: \"{d[data_key[1]]}\"\\n    weight: \"{d[data_key[2]]}\"\\n    worst: \"{d[data_key[3]]}\"')\n",
    "        \n",
    "    if elements_in_file > elements_to_write:\n",
    "        for i in range(elements_to_write, elements_in_file):\n",
    "            contents = re.sub(fr\"(solution_comparison{i}: .*\\n    time_solution: .*\\n    time_scenario: .*\\n    weight: .*\\n    worst: .*\\n)\", \n",
    "                              f'solution_comparison{i}: \\n    time_solution:\\n    time_scenario:\\n    weight:\\n    worst:\\n', contents)\n",
    "\n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_comparison0: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison1: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison2: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison3: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison4: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison5: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison6: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison7: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison8: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison9: \n",
      "    time_solution:\n",
      "    time_scenario:\n",
      "    weight:\n",
      "    worst:\n",
      "solution_comparison0: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight2\"\n",
      "    worst: \"False\"solution_comparison1: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"solution_comparison2: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"morning\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"solution_comparison3: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"midday\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"solution_comparison4: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"afternoon\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"False\"solution_comparison5: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight2\"\n",
      "    worst: \"True\"solution_comparison6: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"all_day\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"solution_comparison7: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"morning\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"solution_comparison8: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"midday\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"solution_comparison9: \n",
      "    time_solution: \"all_day_free_flow\"\n",
      "    time_scenario: \"afternoon\"\n",
      "    weight: \"weight\"\n",
      "    worst: \"True\"\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data cleaning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_general_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters.yml\"\n",
    "root_visualization_params = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\parameters\\visualization.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [[f\"{day}_04_2023\"]*3 for day in range(20, 22)]\n",
    "times = [[\"morning\", \"midday\", \"afternoon\"] for day in range(20, 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_visualization_params, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "    elements_in_file = len(re.findall(r\"(visualization.date\\d: .*\\n)\", contents))\n",
    "    m_dates_to_write = len(dates)\n",
    "    \n",
    "    if elements_in_file < m_dates_to_write:\n",
    "        s=\"\"\n",
    "        if elements_in_file == 0:\n",
    "            for i in range(0, m_dates_to_write):\n",
    "                for j in range(0, len(dates[i])):\n",
    "                    s += f'visualization.date{i}{j}: \\n    day: \\n    time: \\n'\n",
    "            contents = \"\\n\".join([s])\n",
    "        else:\n",
    "            start = elements_in_file-1\n",
    "            for j in range(0, len(dates[start])):\n",
    "                s += f'visualization.date{start}{j}: \\n    day: \\n    time: \\n'\n",
    "            for i in range(elements_in_file, m_dates_to_write):\n",
    "                for j in range(0, len(dates[i])):\n",
    "                    s += f'visualization.date{i}{j}: \\n    day: \\n    time: \\n'\n",
    "            contents = re.sub(fr\"(visualization.date{elements_in_file-1}: .*\\n)\", s, contents)\n",
    "            \n",
    "    for i, (date, time) in enumerate(zip(dates, times)):\n",
    "        for j, (d, t) in enumerate(zip(date, time)):\n",
    "            contents = re.sub(fr\"(visualization.date{i}{j}: .*\\n    day: .*\\n    time: .*\\n)\", \n",
    "                          f'visualization.date{i}{j}: \\n    day: \"{d}\"\\n    time: \"{t}\"\\n', contents)\n",
    "    \n",
    "    if elements_in_file > m_dates_to_write:\n",
    "        for i in range(m_dates_to_write, elements_in_file+1):\n",
    "            for j in range(0, len(dates[i])):\n",
    "                contents = re.sub(fr\"(visualization.date{i}{j}: .*\\n    day: .*\\n    time: .*\\n)\", \n",
    "                              f'visualization.date{i}{j}: \\n    day: \\n    time: \\n', contents)\n",
    "\n",
    "    \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualization.date00: \n",
      "    day: \"20_04_2023\"\n",
      "    time: \"morning\"\n",
      "visualization.date01: \n",
      "    day: \"20_04_2023\"\n",
      "    time: \"midday\"\n",
      "visualization.date02: \n",
      "    day: \"20_04_2023\"\n",
      "    time: \"afternoon\"\n",
      "visualization.date10: \n",
      "    day: \"21_04_2023\"\n",
      "    time: \"morning\"\n",
      "visualization.date11: \n",
      "    day: \"21_04_2023\"\n",
      "    time: \"midday\"\n",
      "visualization.date12: \n",
      "    day: \"21_04_2023\"\n",
      "    time: \"afternoon\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in contents.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooth_catalog_path = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\conf\\base\\catalog.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_catalog_path, \"r+\") as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "    elements_in_file = len(re.findall(r\"(visualization.date\\d: .*\\n)\", contents))\n",
    "    m_dates_to_write = len(dates)\n",
    "    \n",
    "    if elements_in_file < m_dates_to_write:\n",
    "        s=\"\"\n",
    "        if elements_in_file == 0:\n",
    "            for i in range(0, m_dates_to_write):\n",
    "                for j in range(0, len(dates[i])):\n",
    "                    s += f'visualization.date{i}{j}: \\n    day: \\n    time: \\n'\n",
    "            contents = \"\\n\".join([s])\n",
    "        else:\n",
    "            start = elements_in_file-1\n",
    "            for j in range(0, len(dates[start])):\n",
    "                s += f'visualization.date{start}{j}: \\n    day: \\n    time: \\n'\n",
    "            for i in range(elements_in_file, m_dates_to_write):\n",
    "                for j in range(0, len(dates[i])):\n",
    "                    s += f'visualization.date{i}{j}: \\n    day: \\n    time: \\n'\n",
    "            contents = re.sub(fr\"(visualization.date{elements_in_file-1}: .*\\n)\", s, contents)\n",
    "            \n",
    "    for i, (date, time) in enumerate(zip(dates, times)):\n",
    "        for j, (d, t) in enumerate(zip(date, time)):\n",
    "            contents = re.sub(fr\"(visualization.date{i}{j}: .*\\n    day: .*\\n    time: .*\\n)\", \n",
    "                          f'visualization.date{i}{j}: \\n    day: \"{d}\"\\n    time: \"{t}\"\\n', contents)\n",
    "    \n",
    "    if elements_in_file > m_dates_to_write:\n",
    "        for i in range(m_dates_to_write, elements_in_file+1):\n",
    "            for j in range(0, len(dates[i])):\n",
    "                contents = re.sub(fr\"(visualization.date{i}{j}: .*\\n    day: .*\\n    time: .*\\n)\", \n",
    "                              f'visualization.date{i}{j}: \\n    day: \\n    time: \\n', contents)\n",
    "\n",
    "    \n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
