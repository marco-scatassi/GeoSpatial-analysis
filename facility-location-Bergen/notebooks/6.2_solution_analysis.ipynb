{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\src\\facility_location_Bergen\\custome_modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "# Ignore the ShapelyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import pyproj\n",
    "import folium\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.utils import resample\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from plotly.subplots import make_subplots\n",
    "from urllib.request import urlopen, Request\n",
    "from log import print_INFO_message_timestamp, print_INFO_message\n",
    "from facility_location import AdjacencyMatrix, FacilityLocation, FacilityLocationReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [\"all_day\", \"all_day_free_flow\", \"morning\", \"midday\", \"afternoon\"]\n",
    "facilities_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/19/23 12:41:59] INFO     Loading exact solutions...\n",
      "                    INFO     Loading exact solution for all_day\n"
     ]
    }
   ],
   "source": [
    "print_INFO_message_timestamp(\"Loading exact solutions...\")\n",
    "\n",
    "fls_exact = {}\n",
    "\n",
    "for time in times[:1]:\n",
    "    print_INFO_message(f\"Loading exact solution for {time}\")\n",
    "    path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\07_model_output\\{facilities_number}_locations\\deterministic_exact_solutions\\exact_solution_{time}.pkl\"\n",
    "    fls_exact[time] = FacilityLocation.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prova.txt\", \"w\") as f:\n",
    "    fls_exact[\"all_day\"].instance.pprint(ostream=f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dfs for solution comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\08_reporting\"\n",
    "paths = [p for p in os.listdir(root) if (\"solution_vs_scenario\" in p) and (\"worst\" not in p)]\n",
    "paths_worst = [p for p in os.listdir(root) if (\"solution_vs_scenario\" in p) and (\"worst\" in p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "for path in paths:\n",
    "    with open(os.path.join(root, path), \"rb\") as f:\n",
    "        dfs[tuple(path.removesuffix(\".pkl\").split(\"_\")[-2:])] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_worst = {}\n",
    "\n",
    "for path in paths_worst:\n",
    "    with open(os.path.join(root, path), \"rb\") as f:\n",
    "        dfs_worst[tuple(path.removesuffix(\".pkl\").split(\"_\")[-3:-1])] = pkl.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adj matrix mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mappings = {}\n",
    "\n",
    "for time in times:\n",
    "    if time != \"all_day_free_flow\":\n",
    "        print_INFO_message(f\"Loading adj mapping for {time}\")\n",
    "        path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\03_primary\\adj_mapping_{time}.pkl\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            adj_mappings[time] = dill.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_graphs = {}\n",
    "\n",
    "for time in times:\n",
    "    if time != \"all_day_free_flow\":\n",
    "        print_INFO_message(f\"Loading adj matrix for {time}\")\n",
    "        path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\03_primary\\average_graph_{time}.pkl\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            average_graphs[time] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_average_graphs = {}\n",
    "\n",
    "for time in times:\n",
    "    if time != \"all_day_free_flow\":\n",
    "        print_INFO_message(f\"Loading adj matrix for {time}\")\n",
    "        path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\03_primary\\worst_average_graph_{time}.pkl\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            worst_average_graphs[time] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact solution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_INFO_message_timestamp(\"Objective value for the Exact solution\")\n",
    "for time, fl_exact in fls_exact.items():\n",
    "    print_INFO_message(f\"{time}: {round(fl_exact.solution_value/60,3)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_exact = FacilityLocationReport(fls_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_exact.graphical_keys_solutions_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let O denote the objective function, t denote time, and x denotes the decision variables. \n",
    "- Let x_ff be the value of the decision variables obtained in the free-flow setting. \n",
    "\n",
    "For each time condition t, we want to compute the value of the objective function O(x_ff, t) when fixing x to be x_ff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve average graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fls_exact[\"all_day_free_flow\"].locations_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = fls_exact[\"all_day_free_flow\"].solution_value/60\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fls_exact[\"all_day_free_flow\"].adjacency_matrix\n",
    "print(a.shape)\n",
    "np.where(a/60 == sv, a, 0).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'source: {adj_mappings[\"all_day\"][1442]}\\ndestination: {adj_mappings[\"all_day\"][646]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nx.dijkstra_path_length(G=average_graphs[\"all_day\"], \n",
    "                            source=adj_mappings[\"all_day\"][1442], \n",
    "                            target=adj_mappings[\"all_day\"][646],\n",
    "                            weight=\"weight2\")/60\n",
    "\n",
    "b = fls_exact[\"all_day_free_flow\"].adjacency_matrix[1442, 646]/60\n",
    "\n",
    "print(f\"shortest path lenght: {a}\\nadj matrix: {b}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare solution under different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_vs_scenario(time_solution, time_scenario, weight=\"weight2\", worst=False):\n",
    "    \n",
    "    # Load the exact solution\n",
    "    print_INFO_message_timestamp(f\"Loading exact solution for {time_solution}\")\n",
    "    path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\07_model_output\\exact_solutions\\exact_solution_{time_solution}.pkl\"\n",
    "    fls_exact_solution = FacilityLocation.load(path)\n",
    "    \n",
    "    # Load the average graph\n",
    "    print_INFO_message(f\"Loading adj matrix for {time_scenario}\")\n",
    "    if worst:\n",
    "        path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\03_primary\\worst_average_graph_{time_scenario}.pkl\"\n",
    "    else:\n",
    "        path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\03_primary\\average_graph_{time_scenario}.pkl\"\n",
    "    \n",
    "    with open(path, \"rb\") as f:\n",
    "        average_graph = pkl.load(f)\n",
    "    \n",
    "    # extract the coordinates of the exact solution\n",
    "    ff_solutions_location = fls_exact_solution.locations_coordinates\n",
    "    \n",
    "    # compute the distance from the exact solution to all the other nodes in the graph\n",
    "    print_INFO_message_timestamp(f\"Compute the distance from the {time_solution} solution to all the other nodes in the {time_scenario} graph\")\n",
    "    \n",
    "    temporal_distances = {ff_solutions_location[i].geometry.coords[0]: [] for i in range(len(ff_solutions_location))}\n",
    "\n",
    "    for i, node in enumerate(average_graph):\n",
    "        if i%500 == 0:\n",
    "            print_INFO_message(f\"{i} out of {len(average_graph.nodes)}\")\n",
    "            \n",
    "        keys = list(temporal_distances.keys())\n",
    "        temporal_distances[keys[0]].append(\n",
    "            (node, nx.dijkstra_path_length(G=average_graph, \n",
    "                                source=keys[0], \n",
    "                                target=node,\n",
    "                                weight=weight))\n",
    "            ) \n",
    "        \n",
    "        temporal_distances[keys[1]].append(\n",
    "            (node, nx.dijkstra_path_length(G=average_graph, \n",
    "                                source=keys[1], \n",
    "                                target=node,\n",
    "                                weight=weight))\n",
    "            )\n",
    "    \n",
    "    # create a dataframe with the distance from the exact solution to all the other nodes in the graph\n",
    "    d = {\"source\": [], \"target\": [], \"travel_time\": []}\n",
    "    \n",
    "    for key, value in temporal_distances.items():\n",
    "        for node, distance in value:\n",
    "            d[\"source\"].append(key)\n",
    "            d[\"target\"].append(node)\n",
    "            d[\"travel_time\"].append(round(distance/60, 3))\n",
    "            \n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_distances(df):\n",
    "    return df.groupby(\"target\").min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dfs.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Free-flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_day_ff_min = get_minimum_distances(dfs[(\"day\", \"weight2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_day_ff_min.sort_values(by=\"travel_time\", ascending=False).reset_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_day_ff_min[\"travel_time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round(fls_exact[\"all_day_free_flow\"].solution_value/60, 3)\n",
    "b = dfs[(\"day\", \"weight2\")].groupby(\"target\").min().sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "\n",
    "print(f\"exact solution: {a}\\nff approximation: {b}\\nrel_difference: {round(abs(a-b)/a * 100,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_day_min = get_minimum_distances(dfs[(\"day\", \"weight\")])\n",
    "df_worst_all_day_min = get_minimum_distances(dfs_worst[(\"day\", \"weight\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'average time: {df_all_day_min[\"travel_time\"].mean()}\\naverage worst time: {df_worst_all_day_min[\"travel_time\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round(fls_exact[\"all_day\"].solution_value/60, 3)\n",
    "\n",
    "b = df_all_day_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "b_worst = df_worst_all_day_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "\n",
    "rel_difference_all_day = round(abs(a-b)/a * 100,3)\n",
    "rel_difference_all_day_worst = round(abs(a-b_worst)/a * 100,3)\n",
    "\n",
    "print(f\"exact solution: {a}\\nff approximation: {b}\\nrel_difference: {rel_difference_all_day}\\nrel_difference_worst: {rel_difference_all_day_worst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morning_min = get_minimum_distances(dfs[(\"morning\", \"weight\")])\n",
    "df_worst_morning_min = get_minimum_distances(dfs_worst[(\"morning\", \"weight\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'average time: {df_morning_min[\"travel_time\"].mean()}\\naverage worst time: {df_worst_morning_min[\"travel_time\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round(fls_exact[\"morning\"].solution_value/60, 3)\n",
    "\n",
    "b = df_morning_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "b_worst = df_worst_morning_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "\n",
    "rel_difference_morning = round(abs(a-b)/a * 100,3)\n",
    "rel_difference_morning_worst = round(abs(a-b_worst)/a * 100,3)\n",
    "\n",
    "print(f\"exact solution: {a}\\nff approximation: {b}\\nrel_difference: {rel_difference_morning}\\nrel_difference_worst: {rel_difference_morning_worst}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Midday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_midday_min = get_minimum_distances(dfs[(\"midday\", \"weight\")])\n",
    "df_worst_midday_min = get_minimum_distances(dfs_worst[(\"midday\", \"weight\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'average time: {df_midday_min[\"travel_time\"].mean()}\\naverage worst time: {df_worst_midday_min[\"travel_time\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round(fls_exact[\"midday\"].solution_value/60, 3)\n",
    "\n",
    "b = df_midday_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "b_worst = df_worst_midday_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "\n",
    "rel_difference_midday = round(abs(a-b)/a * 100,3)\n",
    "rel_difference_midday_worst = round(abs(a-b_worst)/a * 100,3)\n",
    "\n",
    "print(f\"exact solution: {a}\\nff approximation: {b}\\nrel_difference: {rel_difference_midday}\\nrel_difference_worst: {rel_difference_midday_worst}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afternoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afternoon_min = get_minimum_distances(dfs[(\"afternoon\", \"weight\")])\n",
    "df_worst_afternoon_min = get_minimum_distances(dfs_worst[(\"afternoon\", \"weight\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'average time: {df_afternoon_min[\"travel_time\"].mean()}\\naverage worst time: {df_worst_afternoon_min[\"travel_time\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round(fls_exact[\"afternoon\"].solution_value/60, 3)\n",
    "\n",
    "b = df_afternoon_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "b_worst = df_worst_afternoon_min.sort_values(by=\"travel_time\", ascending=False).iloc[0].travel_time\n",
    "\n",
    "rel_difference_afternoon = round(abs(a-b)/a * 100,3)\n",
    "rel_difference_afternoon_worst = round(abs(a-b_worst)/a * 100,3)\n",
    "\n",
    "print(f\"exact solution: {a}\\nff approximation: {b}\\nrel_difference: {rel_difference_afternoon}\\nrel_difference_worst: {rel_difference_afternoon_worst}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the following steps are performed:\n",
    "1. **Compare the objective function value** under different scenarios, for a specif set of solution locations\n",
    "   \n",
    "2. Given the matrix containing the travel times between all OD pairs, for a specific solution, **compare the distribution** of travel times between OD pairs under different scenarios\n",
    "   \n",
    "3. **Dispaly the path** associated to the solutions at step1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Compare the objective function value under different scenarios, for a specif set of solution locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_diffs = [rel_difference_all_day, rel_difference_morning, rel_difference_midday, rel_difference_afternoon]\n",
    "rel_diffs_worst = [rel_difference_all_day_worst, rel_difference_morning_worst, rel_difference_midday_worst, rel_difference_afternoon_worst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2,)\n",
    "fig.update_layout(title=\"<b>Relative difference between the exact solution and the free flow approximation<b>\",\n",
    "                  title_pad_l=150,\n",
    "                  height=500,\n",
    "                  width=1200,\n",
    "                  yaxis_title=\"relative difference [%]\")\n",
    "\n",
    "fig.update_yaxes(range=[0, 100])\n",
    "\n",
    "fig.add_trace(go.Bar(y=rel_diffs, \n",
    "                     name=\"average scenario\",\n",
    "                     x=[\"all_day\", \"morning\", \"midday\", \"afternoon\"],), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(y=rel_diffs_worst,\n",
    "                     name=\"average worst scenario\",\n",
    "                     x=[\"all_day\", \"morning\", \"midday\", \"afternoon\"],), row=1, col=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Compare the distribution of travel times between OD pairs under different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = df_all_day_ff_min[[\"target\", \"travel_time\"]]\n",
    "\n",
    "for df, name in zip([df_all_day_min, df_morning_min, df_midday_min, df_afternoon_min, \n",
    "                     df_worst_all_day_min, df_worst_morning_min, df_worst_midday_min, df_worst_afternoon_min], \n",
    "                    [\"all_day\", \"morning\", \"midday\", \"afternoon\", \"worst_all_day\", \"worst_morning\", \"worst_midday\", \"worst_afternoon\"]):\n",
    "    \n",
    "    df_min = df_min.merge(df[[\"target\", \"travel_time\"]], \n",
    "                          on=\"target\", \n",
    "                          suffixes=(None, \"_\"+name),\n",
    "                          how=\"outer\")\n",
    "\n",
    "df_min = df_min.rename(columns={\"travel_time\": \"travel_time_free_flow\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "show_legend = [True]+[False]*len(df_min.columns[1:])\n",
    "\n",
    "fig.update_layout(title=\"<b>Distribution for free flow travel times solution across average scenarios<b>\",\n",
    "                  title_pad_l=150,\n",
    "                  height=500,\n",
    "                  width=1200,\n",
    "                  xaxis_title=\"time of the day\",)\n",
    "\n",
    "fig.update_yaxes(range=[0, 40])\n",
    "\n",
    "for i, name in enumerate([\"free_flow\", \"all_day\", \"morning\", \"midday\", \"afternoon\",\n",
    "                          \"worst_all_day\", \"worst_morning\", \"worst_midday\", \"worst_afternoon\"]):\n",
    "    fig.add_trace(go.Violin(y=df_min[\"travel_time_free_flow\"],\n",
    "                            name=name,\n",
    "                            box_visible=True,\n",
    "                            meanline_visible=False,\n",
    "                            hoverinfo=\"none\",\n",
    "                            side=\"negative\",\n",
    "                            line_color=\"lightseagreen\",\n",
    "                            showlegend=show_legend[i]))\n",
    "    \n",
    "    fig.add_trace(go.Violin(y=df_min[\"travel_time_\"+name],\n",
    "                            name=name,\n",
    "                            box_visible=True,\n",
    "                            meanline_visible=False,\n",
    "                            hoverinfo=\"none\",\n",
    "                            side=\"positive\",\n",
    "                            line_color=\"mediumpurple\",\n",
    "                            showlegend=show_legend[-1]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U test\n",
    "for col in df_min.columns[2:]:\n",
    "    print_INFO_message_timestamp(f\"Performing Mann-Whitney U test for {col}\")\n",
    "    statistic, p_value = stats.mannwhitneyu(df_min[\"travel_time_free_flow\"], df_min[col])\n",
    "\n",
    "    # Print the results\n",
    "    print_INFO_message(f\"Mann-Whitney U statistic: {statistic}\")\n",
    "    print_INFO_message(f\"P-value: {p_value}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ci = pd.DataFrame({\"mean\": None, \"lower_bound\": None, \"upper_bound\": None}, \n",
    "                       index=df_min.columns[1:])\n",
    "\n",
    "for col in df_min.columns[1:]:\n",
    "    # Number of bootstrap iterations\n",
    "    n_iterations = 1000\n",
    "\n",
    "    # Confidence level (e.g., 95%)\n",
    "    confidence_level = 0.95\n",
    "\n",
    "    # Array to store bootstrap sample statistics\n",
    "    bootstrap_means = []\n",
    "\n",
    "    # Perform bootstrap iterations\n",
    "    for _ in range(n_iterations):\n",
    "        bootstrap_sample = resample(df_min[col], replace=True, n_samples=len(df_min))\n",
    "        bootstrap_mean = np.mean(bootstrap_sample)\n",
    "        bootstrap_means.append(bootstrap_mean)\n",
    "\n",
    "    # Compute confidence interval\n",
    "    lower_bound = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
    "\n",
    "    # Add to dataframe\n",
    "    mean_ci.loc[col] = [df_min[col].mean(), lower_bound, upper_bound]\n",
    "    \n",
    "# Print the confidence interval\n",
    "mean_ci = mean_ci.sort_values(by=\"mean\", ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.update_layout(title=\"<b>Average travel time for free flow solution across average scenarios<b>\",\n",
    "                  title_pad_l=130,\n",
    "                  height=600,\n",
    "                  width=1100,\n",
    "                  xaxis_title=\"time of the day\",\n",
    "                  yaxis_title=\"mean travel time [min]\")\n",
    "\n",
    "fig.add_trace(go.Bar(x=mean_ci.index, \n",
    "                     y = mean_ci[\"mean\"],\n",
    "                     width=0.5,\n",
    "                     name='mean'))\n",
    "\n",
    "# Add the vertical line\n",
    "for col in df_min.columns[1:]:\n",
    "        fig.add_shape(type='line',\n",
    "                x0=col, y0=mean_ci.loc[col][\"lower_bound\"],\n",
    "                x1=col, y1=mean_ci.loc[col][\"upper_bound\"],\n",
    "                xref='x', yref='y',\n",
    "                line=dict(color='red', width=10))\n",
    "\n",
    "fig.update_yaxes(range=[0, mean_ci[\"upper_bound\"].max()+1])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Dispaly the path associated to the solutions at step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = \"all_day\"\n",
    "print_INFO_message_timestamp(f\"Loading gdf for {time}\")\n",
    "path = rf\"C:\\Users\\Marco\\Documents\\GitHub\\GeoSpatial-analysis\\facility-location-Bergen\\data\\03_primary\\average_{time}.geojson\"\n",
    "with open(path, \"rb\") as f:\n",
    "    all_day_gdf = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, destination = df_all_day_ff_min.sort_values(by=\"travel_time\", ascending=False).iloc[0][[\"source\", \"target\"]]\n",
    "solution_path = nx.dijkstra_path(G=average_graphs[\"all_day\"], source=source, target=destination, weight=\"weight2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_travel_time(solution_path, graph):\n",
    "    travel_time = 0\n",
    "    for i in range(len(solution_path)-1):\n",
    "        sp = solution_path[i]\n",
    "        ep = solution_path[i+1]\n",
    "        travel_time += graph.get_edge_data(sp, ep)[\"weight\"]\n",
    "    return travel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time = {}\n",
    "\n",
    "for time in [\"free_flow\"]+ ['all_day', 'morning', 'midday', 'afternoon']:\n",
    "    if time == \"free_flow\":\n",
    "        travel_time[time] = nx.dijkstra_path_length(G=average_graphs[\"all_day\"], source=source, target=destination, weight=\"weight2\")\n",
    "    else:\n",
    "        travel_time[time] = get_travel_time(solution_path, average_graphs[time])\n",
    "    minutes = int(travel_time[time]/60)\n",
    "    seconds = int(travel_time[time]%60)\n",
    "    travel_time[time] = str(minutes) + \" min\" + \" \" + str(seconds) + \" sec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in ['all_day', 'morning', 'midday', 'afternoon']:\n",
    "    travel_time[time+\"_worst\"] = get_travel_time(solution_path, worst_average_graphs[time])\n",
    "    minutes = int(travel_time[time+\"_worst\"]/60)\n",
    "    seconds = int(travel_time[time+\"_worst\"]%60)\n",
    "    travel_time[time+\"_worst\"] = str(minutes) + \" min\" + \" \" + str(seconds) + \" sec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in travel_time.keys():\n",
    "    print(f\"travel time {time}: {travel_time[time]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_pt = [60.39299, 5.32415]\n",
    "map = folium.Map(location=center_pt, tiles=\"OpenStreetMap\", zoom_start=11)\n",
    "\n",
    "tooltip = \"<br><br>\".join([rf\"<b>travel time {time}</b>: \" + travel_time[time] for time in [\"free_flow\"]+\n",
    "                           ['all_day', 'morning', 'midday', 'afternoon']+\n",
    "                           ['all_day_worst', 'morning_worst', 'midday_worst', 'afternoon_worst']])\n",
    "\n",
    "folium.PolyLine(locations=[(node[1], node[0]) for node in solution_path], \n",
    "                color=\"black\",\n",
    "                weight=5,\n",
    "                tooltip=tooltip).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fls_exact[\"all_day\"].__dict__.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (facility_location_Bergen)",
   "language": "python",
   "name": "kedro_facility_location_bergen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
